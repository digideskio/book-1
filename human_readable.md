# Human-readable

## WRITTEN?
## PROOFED?

These are layers that humans can, or should be able to, read.  [diagram?]

## Understanding "readability"

This layer is about the **humans in the home being able to read and understand what's going on**. As much as possible, this layer should convey things in very simple iconography or text. 

The goal is that the users, **regardless of their technical proficiency**, will feel confident in understanding what the object or service is offering, how it proposes to interact with other humans and objects, and any other important information.  

There may be ways in which the other layers will **guide and advise the user**. This could be preventing malicious software from being installed, or conveying to other devices and the outside world that the user does not want to be track. 

**At the human-readable layer, the user should be able to understand that the actions taken on their behalf, and they should have the ability to modify or opt-out of those actions if they choose.**  

In other words, wherever possible, this should not only be a read-only layer, but also one that the inhabitants in the home **can write and execute.** By being conveyed in a simple manner that is understandable to them, yet while offering the ability to modify it to suit their needs, the user gains greater control in their own dwelling. 

This control is essential for people **to live confidently and with dignity** in their home. 

The connected home can be a mysterious, opaque place: Unless we already happen to know the connected devices ("Oh look, a Nest thermostat!") we can't tell what's going on.

**The connected home is not yet human-readable.** 

How do we know what's expected of us as users, residents, visitors? 

There are three aspects to this:

1. How can devices or (increasingly "invisible") services communicate what they require their users to do without being obnoxious?

2. How do we convey to the room what we expect of it? 

3. How does this change depending on which role we are currently in (residents v guests v temporary renters)?

The first aspect might be tackled through increased labeling to make the situation more human-readable: A set of icons to indicate active engagement v passive sensing, for example. This is not very elegant and a stop-gap measure at best. On the machine-readable side of things this might work ok, if we can find standards that make all smart things compatible reliably. From today's point of view, that's still some way off.

![icons](https://raw.githubusercontent.com/understanding-the-connected-home/book/master/img/icons.png)

_The blunt approach of labeling: A set of icons that indicate what is collecting data, what is transmitting data, what is analyzing data. "Does this thing listen or watch? Does it share data to the cloud?" Some possible connected device engagement icons. Source: Noun Project (eye by <a href="https://thenounproject.com/search/?q=eye&amp;i=6186">Thomas Le Bas</a>, ear by <a href="https://thenounproject.com/search/?q=ear&amp;i=6200">SÃ¸ren Michelsen</a>, cloud by <a href="https://thenounproject.com/search/?q=wifi&amp;i=123908">Aaron K. Kim</a>)._


The second aspect is one that right now seems hard to solve from a technological angle if it should happen smoothly in the background. We might just need to explicitly state our needs/wishes: "Ok Google!"

The third aspect requires more nuance and context awareness. Recent advances in algorithmic agents mean we can hope for this to be worked out sooner rather than later, and social norms might help figure out the rest.


## We need interaction models for background connectedness

As connectivity retreats more and more into the background - as it becomes more calm - **legibility for humans might get worse even as quality of life increases.**

This is a clear challenge for the interaction design community, albeit a hard one. 

It's also a challenge not entirely unique to the connected home: In the context of smart cities, wearable tech, and even connected cars we increasingly see similar challenges.

In order to get there, we might need to evolve a vocabulary for all these types of interactions we will be increasingly facing that today we simply don't have the words for.

## Key takeaways

- The connected home is not yet human-readable.
- We need to find a way for the home to communicate its expectation to its users, and vice versa.
- We need to design interaction models for background connectedness.
- We need to evolve our vocabulary for these new types of interactions.



## Human-to-human

This is the most common interaction upon which all of society is based. A home is full of human <> human interaction. 

## Human-to-computer

This is an interaction used most commonly when thinking of products. Single user, single machine. Example: a toaster. 

## Human-to-computers

Increasingly, humans are interacting with multiple machines, or more accurately, systems. 

### Bringing your preferences with you

Lots of current scenarios for smart buildings advertise personalization and adapting to personal preferences, particularly in regards to climate control (temperature, humidity), lighting (colors, brightness), settings (music, mood lighting, window blinds). 

This is legit, and in fact might play an important role - for example, [Philips research suggests](http://www.newscenter.philips.com/main/standard/news/press/2015/20150318-philips-calls-for-a-rethink-of-office-lighting-to-meet-the-needs-of-an-ageing-workforce.wpd) that older workforce requires much brighter light than younger workforce, and that the brightness of light at the workplace has serious impact on well-being.

So upon entering your home, or room (in shared living arrangements), or hotel room/rental apartment (in temporary/travel housing), it would make sense to communicate your preferences to the building so it can adapt accordingly. 

**We are surrounded by a sphere of personal data that moves through time and space with us, and it might linger here and there.**

**Currently, we don't have a universal mechanism to communicate our preferences to a building.** Of course, many home automation companies are working on just that, at varying degrees of standardization. 

**What are the next steps here, what's the big vision?** What kind of data might be interesting to bring into a home, to take out of a home, to take along to a new place? What kind of data might we want to bring along into connected cars? What do we want to share with the smart city in all its manifestations? **These are big research questions.**

**How do we transmit personal data to our environment?** What are the models to transfer all these types of data (preferences, settings, etc.)? Should this happen through the cloud? Through apps and our phones? Should we carry one piece of digital ID (built into the phone or wearables) that just serves as an identifier to then download our things from the internet, or should it all be stored locally? **What do the interaction models look like?**

## Humans-to-computers

With further complexity are interactions among multiple people and complex systems. Think shared living spaces with many devices, services and user preferences.